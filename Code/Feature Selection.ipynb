{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\vish\\Documents\\Data\\Dataset\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearon's correlation\n",
    "# A value of 0 means no correlation. The value must be interpreted, where often a value below -0.5 or above 0.5 \n",
    "# indicates a notable correlation, and values below those values suggests a less notable correlation\n",
    "# f_regression: Used only for numeric targets and based on linear regression performance\n",
    "# null hypotheses - the samples are uncorrelated/independent.\n",
    "# alternate hypotheses - the samples are correlated/dependent.\n",
    "#if the p-value is less than significance level, we can reject null hypotheses and accept alternate hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.198\n",
      "P value : 0.000\n",
      "We reject null hypotheses(H0) and accept alternate hypotheses(H1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, p = pearsonr(df['bmi'], df['charges'])\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('P value : %.3f' % p)\n",
    "\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('We accept null hypotheses(H0)')\n",
    "else:\n",
    "    print('We reject null hypotheses(H0) and accept alternate hypotheses(H1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>0.198341</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bmi   charges\n",
       "bmi      1.000000  0.198341\n",
       "charges  0.198341  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['bmi','charges']]\n",
    "df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman's coefficient\n",
    "#The function takes two real-valued samples as arguments and \n",
    "# returns both the correlation coefficient in the range between -1 and 1 \n",
    "# and the p-value for interpreting the significance of the coefficient.\n",
    "# null hypotheses - the samples are uncorrelated/independent.\n",
    "# alternate hypotheses - the samples are correlated/dependent.\n",
    "#if the p-value is less than significance level, we can reject null hypotheses and accept alternate hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.119\n",
      "P value: 0.000\n",
      "We reject null hypotheses(H0) and accept alternate hypotheses(H1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "corr, p = spearmanr(df['bmi'], df['charges'])\n",
    "print('Spearman correlation: %.3f' % corr)\n",
    "print('P value: %.3f' % p)\n",
    "\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('We accept null hypotheses(H0)')\n",
    "else:\n",
    "    print('We reject null hypotheses(H0) and accept alternate hypotheses(H1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.119396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charges</th>\n",
       "      <td>0.119396</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bmi   charges\n",
       "bmi      1.000000  0.119396\n",
       "charges  0.119396  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df[['bmi','charges']]\n",
    "df2.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearsonâ€™s Chi-Square \n",
    "# print(\"Null Hypotheses - Variables are uncorrelated/independent\")\n",
    "# print(\"Alternate Hypotheses - Variables are correlated/dependent\")\n",
    "# print(\"If statistics/chi value is less than critical value, accept null hypotheses\")\n",
    "# print(\"If statistics/chi value is more than or equal to critical value, reject null hypotheses\")\n",
    "# print(\"if p value is more than significance, accept null hypotheses\")\n",
    "# print(\"if p value is less than or equal to significance, reject null hypotheses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Titanic data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Survived    0    1\n",
      "SibSp             \n",
      "0         398  210\n",
      "1          97  112\n",
      "2          15   13\n",
      "3          12    4\n",
      "4          15    3\n",
      "5           5    0\n",
      "8           7    0\n",
      "alpha=0.05, level_of_significance=0.95, critical=12.592, stat=37.272\n",
      "Dependent (reject H0)\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "crosstab =pd.crosstab(df[\"SibSp\"], df[\"Survived\"])\n",
    "stat, p, dof, expected=chi2_contingency(crosstab)\n",
    "alpha = 0.05\n",
    "level_of_significance = 1 - alpha\n",
    "critical = chi2.ppf(level_of_significance, dof)\n",
    "\n",
    "print('Dataset')\n",
    "print(crosstab)\n",
    "print('alpha=%.2f, level_of_significance=%.2f, critical=%.3f, stat=%.3f' % (alpha, level_of_significance, critical, stat))\n",
    "\n",
    "# interpret test-statistic\n",
    "if abs(stat) >= critical:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')\n",
    "\n",
    "# interpret p-value\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_regression\n",
    "# Used only for numeric targets and based on linear regression performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric input Numeric output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Sonar.csv\",header=None)\n",
    "df=df[[0,1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: (208, 10)\n",
      "Reduced number of features: (208, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "X = df.iloc[:,0:10].values\n",
    "y = df.iloc[:,10].values\n",
    "f_regression_selector = SelectKBest(f_regression, k=2)\n",
    "X_kbest = f_regression_selector.fit_transform(X, y)\n",
    "print('Original number of features:', X.shape)\n",
    "print('Reduced number of features:', X_kbest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical input numeric output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Insurance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "df['sex']= label_encoder.fit_transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder2 = preprocessing.LabelEncoder() \n",
    "# Encode labels in column 'species'. \n",
    "df['smoker']= label_encoder2.fit_transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex']=pd.Categorical(df['sex'])\n",
    "df['children'] = pd.Categorical(df['children'])\n",
    "df=df[['sex','smoker','children','charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: (1338, 3)\n",
      "Reduced number of features: (1338, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "X = df.iloc[:,0:3].values\n",
    "y = df.iloc[:,3].values\n",
    "f_regression_selector = SelectKBest(f_regression, k=2)\n",
    "X_kbest = f_regression_selector.fit_transform(X, y)\n",
    "print('Original number of features:', X.shape)\n",
    "print('Reduced number of features:', X_kbest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2\n",
    "#Performs the chi-square statistic for categorical targets which is less sensible to the nonlinear relationship between the predictive variable and its target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Titanic data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing  \n",
    "label_encoder = preprocessing.LabelEncoder()  \n",
    "df['Sex']= label_encoder.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SibSp']=pd.Categorical(df['SibSp'])\n",
    "df['Survived']=pd.Categorical(df['Survived'])\n",
    "df['Pclass']=pd.Categorical(df['Pclass'])\n",
    "df['Sex']=pd.Categorical(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['SibSp','Pclass','Sex','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 3\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X = df.iloc[:,0:3].values\n",
    "y = df.iloc[:,3].values\n",
    "\n",
    "fvalue_selector = SelectKBest(chi2, k=2)\n",
    "\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create features and target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to categorical data by converting data to integers\n",
    "X = X.astype(int)\n",
    "\n",
    "# Select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "X_kbest = chi2_selector.fit_transform(X, y)\n",
    "\n",
    "# Show results\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_classif\n",
    "#Used only for categorical targets and based on the Analysis of Variance (ANOVA) statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Titanic data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing  \n",
    "label_encoder = preprocessing.LabelEncoder()  \n",
    "df['Sex']= label_encoder.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SibSp']=pd.Categorical(df['SibSp'])\n",
    "df['Survived']=pd.Categorical(df['Survived'])\n",
    "df['Pclass']=pd.Categorical(df['Pclass'])\n",
    "df['Sex']=pd.Categorical(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['SibSp','Pclass','Sex','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 3\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = df.iloc[:,0:3].values\n",
    "y = df.iloc[:,3].values\n",
    "\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create an SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutual Information\n",
    "# Mutual information from the field of information theory is the application of information gain to feature selection.\n",
    "# Used when target variable is categorical\n",
    "# Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable\n",
    "# Mutual information is straightforward when considering the distribution of two discrete (categorical or ordinal) variables such as categorical input and categorical output data.\n",
    "# Nevertheless, it can be adapted for use with numerical input and categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Titanic data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing  \n",
    "label_encoder = preprocessing.LabelEncoder()  \n",
    "df['Sex']= label_encoder.fit_transform(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SibSp']=pd.Categorical(df['SibSp'])\n",
    "df['Survived']=pd.Categorical(df['Survived'])\n",
    "df['Pclass']=pd.Categorical(df['Pclass'])\n",
    "df['Sex']=pd.Categorical(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['SibSp','Pclass','Sex','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 3\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df.iloc[:,0:3].values\n",
    "y = df.iloc[:,3].values\n",
    "\n",
    "fvalue_selector = SelectKBest(mutual_info_classif, k=2)\n",
    "\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric input categorical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create an SelectKBest object to select features with two best ANOVA F-Values\n",
    "fvalue_selector = SelectKBest(mutual_info_classif, k=2)\n",
    "\n",
    "# Apply the SelectKBest object to the features and target\n",
    "X_kbest = fvalue_selector.fit_transform(X, y)\n",
    "\n",
    "print('Original number of features:', X.shape[1])\n",
    "print('Reduced number of features:', X_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True]\n",
      "[2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dataset = datasets.load_iris()\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "dataset = datasets.load_iris()\n",
    "model = LogisticRegression()\n",
    "rfecv = RFECV(estimator=model, cv=10,scoring=\"accuracy\")\n",
    "rfecv=rfecv.fit(dataset.data, dataset.target)\n",
    "print(rfecv.support_)\n",
    "print(rfecv.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True False  True False False  True False\n",
      " False]\n",
      "[4 6 5 1 1 1 9 1 3 7 1 8 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "dataset = datasets.load_boston()\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, 5)\n",
    "rfe = rfe.fit(dataset.data, dataset.target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True  True False  True False False  True False\n",
      "  True]\n",
      "[3 5 4 1 1 1 8 1 2 6 1 7 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "dataset = datasets.load_boston()\n",
    "model = LinearRegression()\n",
    "selector = RFECV(estimator=model, cv=10,scoring=\"neg_mean_squared_error\")\n",
    "selector=selector.fit(dataset.data, dataset.target)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n",
      "9\n",
      "['CRIM', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy as bp\n",
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "dataset_df=pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "print(dataset_df.columns)\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "rf_model = RandomForestRegressor(n_jobs= 4,oob_score= True)\n",
    "feat_selector = bp(rf_model,n_estimators = 'auto', verbose= 0,max_iter= 100)\n",
    "feat_selector.fit(X, y)\n",
    "selected_features = [dataset.feature_names[i] for i, x in enumerate(feat_selector.support_) if x]\n",
    "print(feat_selector.n_features_)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\n",
      "4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy as bp\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "dataset_df=pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "print(dataset_df.columns)\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "rf_model = RandomForestClassifier(n_jobs= 4,oob_score= True)\n",
    "feat_selector = bp(rf_model,n_estimators = 'auto', verbose= 0,max_iter= 100)\n",
    "feat_selector.fit(X, y)\n",
    "selected_features = [dataset.feature_names[i] for i, x in enumerate(feat_selector.support_) if x]\n",
    "print(feat_selector.n_features_)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vish\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1668905  0.04699898 0.43051088 0.35559964]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "dataset = datasets.load_iris()\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0818003  0.03399452 0.50673294 0.37747225]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vish\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dataset = datasets.load_iris()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
