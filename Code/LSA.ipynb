{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "#nltk.download()\n",
    "#python -m nltk.downloader all - from command line\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import defaultdict\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim import corpora,models\n",
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# stop_words = stopwords.words('english')\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# texts = []\n",
    "# for i in doc_set:\n",
    "#     raw = i.lower()\n",
    "#     tokens = tokenizer.tokenize(raw)\n",
    "#     stopped_tokens = [i for i in tokens if not i in stop_words]\n",
    "#     lemmatized_tokens = ' '.join([lemmatizer.lemmatize(i) for i in stopped_tokens])\n",
    "#     texts.append(lemmatized_tokens)\n",
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brocolli', 'good', 'eat', 'brother', 'like', 'eat', 'good', 'brocolli', 'mother'], ['mother', 'spends', 'lot', 'time', 'driving', 'brother', 'around', 'baseball', 'practice'], ['health', 'expert', 'suggest', 'driving', 'may', 'cause', 'increased', 'tension', 'blood', 'pressure'], ['often', 'feel', 'pressure', 'perform', 'well', 'school', 'mother', 'never', 'seems', 'drive', 'brother', 'better'], ['health', 'professional', 'say', 'brocolli', 'good', 'health']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "texts = []\n",
    "for i in doc_set:\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(i) for i in stopped_tokens]\n",
    "    texts.append(lemmatized_tokens)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Vectorization\n",
    "# Count_vect = CountVectorizer()\n",
    "# Count_vect.fit(texts)\n",
    "# Doc_term_matrix_count_vectorizer = Count_vect.transform(texts)\n",
    "# print('Representation of Corpus:')\n",
    "# print(pd.DataFrame(Doc_term_matrix_count_vectorizer.toarray(),columns=Count_vect.get_feature_names()))\n",
    "\n",
    "# #Model Building\n",
    "# svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n",
    "# svd_model.fit(Doc_term_matrix_count_vectorizer)\n",
    "# terms = Count_vect.get_feature_names()\n",
    "# for i, comp in enumerate(svd_model.components_):\n",
    "#     terms_comp = zip(terms, comp)\n",
    "#     sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:4]\n",
    "#     print(\"Topic \"+str(i)+\": \")\n",
    "#     for t in sorted_terms:\n",
    "#         print(t[0],t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(33 unique tokens: ['brocolli', 'brother', 'eat', 'good', 'like']...)\n",
      "[[(0, 2), (1, 1), (2, 2), (3, 2), (4, 1), (5, 1)], [(1, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(8, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)], [(1, 1), (5, 1), (19, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)], [(0, 1), (3, 1), (16, 2), (31, 1), (32, 1)]]\n",
      "[(0, '0.457*\"good\" + 0.457*\"brocolli\" + 0.377*\"eat\"'), (1, '-0.305*\"good\" + -0.305*\"brocolli\" + 0.299*\"pressure\"')]\n",
      "\n",
      "Coherence Score:  0.3160210901215216\n",
      "\n",
      "Coherence Score:  -12.776541787339937\n"
     ]
    }
   ],
   "source": [
    "#Vectorization\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "print(dictionary)\n",
    "print(bow_corpus)\n",
    "\n",
    "#Model Building\n",
    "lsamodel_bow_corpus = LsiModel(bow_corpus, num_topics=2,id2word = dictionary)\n",
    "# corpus ({iterable of list of (int, float), scipy.sparse.csc}, optional) – Stream of document vectors or \n",
    "# a sparse matrix of shape (num_documents, num_terms).\n",
    "# num_topics (int, optional) – Number of requested factors (latent dimensions)\n",
    "# id2word (dict of {int: str}, optional) – ID to word mapping, optional.\n",
    "# chunksize (int, optional) – Number of documents to be used in each training chunk.\n",
    "# decay (float, optional) – Weight of existing observations relatively to new ones.\n",
    "# distributed (bool, optional) – If True - distributed mode (parallel execution on several machines) will be used.\n",
    "# onepass (bool, optional) – Whether the one-pass algorithm should be used for training. \n",
    "# Pass False to force a multi-pass stochastic algorithm.\n",
    "# power_iters (int, optional) – Number of power iteration steps to be used. \n",
    "# Increasing the number of power iterations improves accuracy, but lowers performance\n",
    "# extra_samples (int, optional) – Extra samples to be used besides the rank k. Can improve accuracy.\n",
    "# dtype (type, optional) – Enforces a type for elements of the decomposed matrix\n",
    "print(lsamodel_bow_corpus.print_topics(num_topics=2, num_words=3))\n",
    "\n",
    "#Evaluating the model\n",
    "coherence_model_lda = models.CoherenceModel(model=lsamodel_bow_corpus, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = models.CoherenceModel(model=lsamodel_bow_corpus, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vectorization\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Tfidf_vect = TfidfVectorizer()\n",
    "# Tfidf_vect.fit(texts)\n",
    "# Doc_term_matrix_tfidf_vectorizer = Tfidf_vect.transform(texts)\n",
    "# print('Representation of Corpus:')\n",
    "# print(pd.DataFrame(Doc_term_matrix_tfidf_vectorizer.toarray(),columns=Tfidf_vect.get_feature_names()))\n",
    "\n",
    "# # Model Building\n",
    "# svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n",
    "# svd_model.fit(Doc_term_matrix_tfidf_vectorizer)\n",
    "# terms = Tfidf_vect.get_feature_names()\n",
    "# for i, comp in enumerate(svd_model.components_):\n",
    "#     terms_comp = zip(terms, comp)\n",
    "#     sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:4]\n",
    "#     print(\"Topic \"+str(i)+\": \")\n",
    "#     for t in sorted_terms:\n",
    "#         print(t[0],t[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(33 unique tokens: ['brocolli', 'brother', 'eat', 'good', 'like']...)\n",
      "[(0, 0.40784451109112935), (1, 0.11368521994734913), (2, 0.7163669735975946), (3, 0.40784451109112935), (4, 0.3581834867987973), (5, 0.11368521994734913)]\n",
      "[(1, 0.12424759593709131), (5, 0.12424759593709131), (6, 0.3914619434234833), (7, 0.3914619434234833), (8, 0.2228684610131362), (9, 0.3914619434234833), (10, 0.3914619434234833), (11, 0.3914619434234833), (12, 0.3914619434234833)]\n",
      "[(8, 0.2016345105176491), (13, 0.35416512946544426), (14, 0.35416512946544426), (15, 0.35416512946544426), (16, 0.2016345105176491), (17, 0.35416512946544426), (18, 0.35416512946544426), (19, 0.2016345105176491), (20, 0.35416512946544426), (21, 0.35416512946544426)]\n",
      "[(1, 0.10283764444679584), (5, 0.10283764444679584), (19, 0.18446447498008656), (22, 0.32400646345397865), (23, 0.32400646345397865), (24, 0.32400646345397865), (25, 0.32400646345397865), (26, 0.32400646345397865), (27, 0.32400646345397865), (28, 0.32400646345397865), (29, 0.32400646345397865), (30, 0.32400646345397865)]\n",
      "[(0, 0.2866473576676298), (3, 0.2866473576676298), (16, 0.5732947153352596), (31, 0.5034877128853272), (32, 0.5034877128853272)]\n",
      "[(0, '0.409*\"health\" + 0.400*\"brocolli\" + 0.400*\"good\"'), (1, '0.225*\"driving\" + 0.221*\"spends\" + 0.221*\"baseball\"')]\n",
      "\n",
      "Coherence Score:  0.30322855518435987\n",
      "\n",
      "Coherence Score:  -15.798420967829369\n"
     ]
    }
   ],
   "source": [
    "#Vectorization\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "print(dictionary)\n",
    "for doc in tfidf_corpus:\n",
    "    print(doc)\n",
    "\n",
    "#Model Building\n",
    "lsamodel_tfidf_corpus = LsiModel(tfidf_corpus, num_topics=2,id2word = dictionary)\n",
    "print(lsamodel_tfidf_corpus.print_topics(num_topics=2, num_words=3))\n",
    "\n",
    "#Evaluating the model\n",
    "coherence_model_lda = models.CoherenceModel(model=lsamodel_tfidf_corpus, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "coherence_model_lda = models.CoherenceModel(model=lsamodel_tfidf_corpus, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
