install.packages('caret')
library(caret)
library(forecast)
install.packages("forecast")
install.packages('TTR')
install.packages('fpp2')
data(iris)
head(iris)
data <- iris[, c(1, 2, 5)]
head(data)
data$Species <- factor(ifelse(data$Species == "setosa","rare","common"))
str(data)
table(data$Species)
install.packages('DMwR')
library(DMwR)
newData <- SMOTE(Species ~ ., data, perc.over = 600,perc.under=100)
table(newData$Species)
newData <- SMOTE(Species ~ ., data, perc.over = 600,perc.under=200)
?SMOTE
head(newData)
table(newData$Species)
# ROSE (Random Over Sampling Examples) package -
# Helps in implementing techniques for handling class imbalance
install.packages("ROSE")
library(ROSE)
data(hacide)
head(hacide.train)
str(hacide.train)
# Check for data imbalance
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
# Lets build the logistic regression model on this data
# (without balancing the data)
classifier_imb = glm(cls ~ ., data = hacide.train, family = 'binomial')
summary(classifier_imb)
pred_classifier_imb = predict(classifier_imb, type = 'response', newdata = hacide.test)
y_pred = pred_classifier_imb > 0.5
print(y_pred)
accuracy.meas(hacide.test$cls, pred_classifier_imb)
# Lets also check the model's performance using ROC
# We use the roc.curve function from ROSE for this
roc.curve(hacide.test$cls, pred_classifier_imb)
# Lets now apply oversampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 1960)$data
table(data_balanced_over$cls)
###### Undersampling ######
# Lets now apply undersampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 40)$data
table(data_balanced_under$cls)
###### Undersampling ######
# Lets now apply undersampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
?ovun.sample
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 60)$data
table(data_balanced_under$cls)
# Lets now apply oversampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 2000)$data
table(data_balanced_over$cls)
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 90)$data
table(data_balanced_under$cls)
###### Undersampling & Oversampling ######
# We can apply both these techniques for balancing the data
# p is the approx probability of the positive class in the resulting balanced data
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both",p = 0.5)$data
table(data_balanced_both$cls)
###### Undersampling & Oversampling ######
# We can apply both these techniques for balancing the data
# p is the approx probability of the positive class in the resulting balanced data
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both",p = 0.1)$data
table(data_balanced_both$cls)
###### Synthetic Data Generation (ROSE) ######
# Lets now generate synthetic data using ROSE
data_balanced_rose <- ROSE(cls ~ ., data = hacide.train, p = 0.5)$data
table(data_balanced_rose$cls)
setwd("~/")
setwd("~/Data/Logistic reg")
dataset = read.csv('diabetes.csv')
# Objective Bivariate Analysis (Correlation)
sub_dataset = dataset[-9]
# Split data into training and test sets
library(caTools)
split = sample.split(dataset$Outcome, SplitRatio = 0.75)
train_data = subset(dataset, split == TRUE)
test_data = subset(dataset, split == FALSE)
# Is there class imbalance?
table(dataset$Outcome)
# First version of the model
classifier1 = glm(Outcome ~ ., data = train_data, family = 'binomial')
prob_pred1 = predict(classifier1, type = 'response', newdata = test_data)
# Lets use 0.5 as the threshold to start with
y_pred1 = ifelse(prob_pred1 > 0.5, 1, 0)
table(test_data[,9], y_pred1)
#Use Iris Dataset
attach(iris)
iris
Iris_demo <- iris
View(Iris_demo)
?plot
#Idea behind ploting scater plot is to understand the
#correlation between X and Y
plot(Iris_demo$Sepal.Length,
Iris_demo$Sepal.Width)
points(Iris_demo$Petal.Length,
Iris_demo$Petal.Width,col="red")
?points
points(Iris_demo$Petal.Length,col="blue"
Iris_demo$Petal.Width,col="red")
points(Iris_demo$Petal.Length,col="blue",
Iris_demo$Petal.Width,col="red")
points(Iris_demo$Petal.Length,col="blue",
Iris_demo$Petal.Width)
points(Iris_demo$Petal.Length,
Iris_demo$Petal.Width,col="green")
#Identify the three Species
plot(Iris_demo$Sepal.Length,
Iris_demo$Sepal.Width,
col=Iris_demo$Species)
plot(Iris_demo$Sepal.Length,
Iris_demo$Sepal.Width,
col=Iris_demo$Species)
legend(6.7,4.5,
legend=c("Setosa", "Versicolor",
"Virginica"),
col=c("black","red", "green"),
pch = 1.0)
legend(6.7,4.5,
legend=c("Setosa", "Versicolor",
"Virginica"),
col=c("black","red", "green"),
pch = 2.0)
legend(6.7,4.5,
legend=c("Setosa", "Versicolor",
"Virginica"),
col=c("black","red", "green"),
pch = 1.0)
plot(Iris_demo$Sepal.Length,
Iris_demo$Sepal.Width,type = "p",
col=Iris_demo$Species,
main = "Demo Plot in Iris Dataset",
sub = "Plot example",
xlab = "Length",ylab = "Width")
hist(Iris_demo$Sepal.Width)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
xlab = "Width",
border = "blue",
col = "green",
breaks = c(2,3,4,5)
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
sub"subdemo"
xlab = "Width",
border = "blue",
col = "green",
breaks = c(2,3,4,5)
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
sub="subdemo",
xlab = "Width",
border = "blue",
col = "green",
breaks = c(2,3,4,5)
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
xlab = "Width",
border = "blue",
col = "green",
breaks = 1:6
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
xlab = "Width",
border = "blue",
col = "green",
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
xlab = "Width",
border = "blue",
col = "green",
breaks = 5
)
hist(Iris_demo$Sepal.Width,
main = "Demo Histogram in Iris Dataset",
sub="subdemo",
xlab = "Width",
border = "blue",
col = "green",
breaks = c(2,3,4,5)
)
##density = counts/(n*diff(breaks)
hist(Iris_demo$Sepal.Width,
main = "Density plot",
xlab = "Width",
border = "blue",
col = "green",
breaks = 5,
freq = F
)
##density as parameter (Density of the shading line)
hist(Iris_demo$Sepal.Width,
main = "Freq plot",
xlab = "Width",
border = "blue",
col = "green",
density =  100
)
#Boxplot
#Box plots are extremely useful when you want to understand
#large quantitative information
#Gives you good undestanding of Data distribution
#Very useful if you want to compare data across categories
#Syntax:
#boxplot()
boxplot(Iris_demo$Sepal.Length)
boxplot(Iris_demo)
##Names are not getting fit horizontally in given area.
##I want name to be displayed vertical
##USe "las" parameter
boxplot(Iris_demo,las=2)
#Boxplot
#Box plots are extremely useful when you want to understand
#large quantitative information
#Gives you good undestanding of Data distribution
#Very useful if you want to compare data across categories
#Syntax:
?boxplot()
#RenameName each variables
boxplot(Iris_demo,las=2,
names = c("S_L","S_W",
"P_L","P_W",
"Species"))
##Names are not getting fit horizontally in given area.
##I want name to be displayed vertical
##USe "las" parameter
boxplot(Iris_demo,las=2)
#RenameName each variables
boxplot(Iris_demo,las=2,
names = c("S_L","S_W",
"P_L","P_W",
"Species"))
boxplot(Iris_demo,las=2,
names = c("S_L","S_W",
"P_L","P_W",
"Species"),
col = c("red","green","blue",
"Black","royalblue2"))
boxplot(Iris_demo,las=2,
names = c("S_L","S_W",
"P_L","P_W",
"Species"),
col = c("red","green","blue",
"yellow","royalblue2"))
#Grab the outlier
outlier <- boxplot(Iris_demo$Sepal.Width)
outlier
#Grab the outlier
outlier <- boxplot(Iris_demo$Sepal.Width)
outlier
boxplot(Iris_demo,las=2,
names = c("S_L","S_W",
"P_L","P_W",
"Species"),
col = c("red","green","blue",
"yellow","royalblue2"))
#Grab the outlier
outlier <- boxplot(Iris_demo$Sepal.Width)
outlier
outlier1 <- boxplot(Iris_demo$Sepal.Width,
plot = F)$out
outlier1
##Compare each species type and Petal Length
boxplot(Iris_demo$Petal.Length~Iris_demo$Species,
xlab = "Species Type",
ylab = "Petal Length",
main = "Iris Data",
col = c("red","green","blue"))
##Horizontal Boxplot
boxplot(Iris_demo$Petal.Length~Iris_demo$Species,
xlab = "Species Type",
ylab = "Petal Length",
main = "Iris Data",
col = c("red","green","blue"),
horizontal = T)
outlier1 <- boxplot(Iris_demo$Sepal.Width,
plot = F)$out
outlier1
##Compare each species type and Petal Length
boxplot(Iris_demo$Petal.Length~Iris_demo$Species,
xlab = "Species Type",
ylab = "Petal Length",
main = "Iris Data",
col = c("red","green","blue"))
##Horizontal Boxplot
boxplot(Iris_demo$Petal.Length~Iris_demo$Species,
xlab = "Species Type",
ylab = "Petal Length",
main = "Iris Data",
col = c("red","green","blue"),
horizontal = T)
mytable <- table(iris$Species)
pie(mytable,labels = c("Setosa",
"Versicolor",
"Virginica"))
#Use Pie Percent
pie(mytable,labels =
round(100*mytable/sum(mytable), 1))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = .50,
fill = c("red","green","blue"))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = 1,
fill = c("red","green","blue"))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = 0.75,
fill = c("red","green","blue"))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = 5,
fill = c("red","green","blue"))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = 0.5,
fill = c("red","green","blue"))
#Use Legends
pie(mytable,labels =
round(100*mytable/sum(mytable), 1),
col=c("red","green","blue"))
legend("topright",c("Setosa",
"Versicolor",
"Virginica"),
cex = 0.5,
fill = c("red","green","blue"))
