install.packages('caret')
library(caret)
library(forecast)
install.packages("forecast")
install.packages('TTR')
install.packages('fpp2')
data(iris)
head(iris)
data <- iris[, c(1, 2, 5)]
head(data)
data$Species <- factor(ifelse(data$Species == "setosa","rare","common"))
str(data)
table(data$Species)
install.packages('DMwR')
library(DMwR)
newData <- SMOTE(Species ~ ., data, perc.over = 600,perc.under=100)
table(newData$Species)
newData <- SMOTE(Species ~ ., data, perc.over = 600,perc.under=200)
?SMOTE
head(newData)
table(newData$Species)
# ROSE (Random Over Sampling Examples) package -
# Helps in implementing techniques for handling class imbalance
install.packages("ROSE")
library(ROSE)
data(hacide)
head(hacide.train)
str(hacide.train)
# Check for data imbalance
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
# Lets build the logistic regression model on this data
# (without balancing the data)
classifier_imb = glm(cls ~ ., data = hacide.train, family = 'binomial')
summary(classifier_imb)
pred_classifier_imb = predict(classifier_imb, type = 'response', newdata = hacide.test)
y_pred = pred_classifier_imb > 0.5
print(y_pred)
accuracy.meas(hacide.test$cls, pred_classifier_imb)
# Lets also check the model's performance using ROC
# We use the roc.curve function from ROSE for this
roc.curve(hacide.test$cls, pred_classifier_imb)
# Lets now apply oversampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 1960)$data
table(data_balanced_over$cls)
###### Undersampling ######
# Lets now apply undersampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 40)$data
table(data_balanced_under$cls)
###### Undersampling ######
# Lets now apply undersampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
?ovun.sample
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 60)$data
table(data_balanced_under$cls)
# Lets now apply oversampling for balancing the data
# We use the ovun.sample function from ROSE
# N is the number of data points in the resulting balanced data
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 2000)$data
table(data_balanced_over$cls)
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under",N = 90)$data
table(data_balanced_under$cls)
###### Undersampling & Oversampling ######
# We can apply both these techniques for balancing the data
# p is the approx probability of the positive class in the resulting balanced data
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both",p = 0.5)$data
table(data_balanced_both$cls)
###### Undersampling & Oversampling ######
# We can apply both these techniques for balancing the data
# p is the approx probability of the positive class in the resulting balanced data
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both",p = 0.1)$data
table(data_balanced_both$cls)
###### Synthetic Data Generation (ROSE) ######
# Lets now generate synthetic data using ROSE
data_balanced_rose <- ROSE(cls ~ ., data = hacide.train, p = 0.5)$data
table(data_balanced_rose$cls)
setwd("~/Data/Linear reg")
census=read.csv("income_Census.csv", header=F)
names(census)=c("Age","IndustryCode","Education","Educationnum","maritalstatus","Relationship","Race","Gender","capitalgain","capitalloss","hoursperweek","GT50K")
str(census)
#homonym sol
#rename column names
colnames(census)[1]="AGE"
colnames(census)[c(1 ,2 ,3)]=c("Age","Industrycode","education")
#synonyms sol
#deleting useless column
df2$name=NULL
name=c("Anne","Anne","Pete","Cath","Cath","Cath")
age=c(28,28,30,25,29,35)
child=c(FALSE,FALSE,TRUE,FALSE,TRUE,TRUE)
df2=data.frame(name,age,child)
duplicated(df2)
sum(duplicated(census))
unique(df2)
#Removing duplicate-second way
df2[!duplicated(df2),]
duplicated(df2$name)
#homonym sol
#rename column names
colnames(census)[1]="AGE"
colnames(census)[c(1 ,2 ,3)]=c("Age","Industrycode","education")
#synonyms sol
#deleting useless column
df2$name=NULL
is.na(census$Age)
sum(is.na(census$Age))
which(is.na(census$Age))
which(is.na(census))
df = read.csv("Churn_MV.csv")
df1 <- df[is.na(df$Churn)==FALSE,]
df2 <- df[is.na(df)==FALSE,]
df<-df1
table( df$Churn) ## freq table
df_num <- df[,-c(8,9,10,20:22)]
df_cat <- df[,c(8,9,10,20:22)]
colnames(df_num)
